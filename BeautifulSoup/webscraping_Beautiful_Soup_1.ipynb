{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Summary of the Code:***\n",
        "\n",
        "## The code is a web scraper that fetches quotes and their authors from a sample website designed for web scraping practice.\n",
        "\n",
        "# ***Website Used***:\n",
        "\n",
        "- The website used is ***Quotes to Scrape***.\n",
        "- It’s a testing site specifically created for practicing web scraping techniques.\n",
        "Key Components of the Code:\n",
        "\n",
        "- **Library Installation**: It installs the requests and BeautifulSoup libraries to facilitate web requests and HTML parsing.\n",
        "- **Web Request:** It sends an HTTP GET request to the Quotes to Scrape URL and retrieves the webpage content.\n",
        "- **HTML Parsing:** The HTML content is parsed using BeautifulSoup to facilitate data extraction.\n",
        "- **Data Extraction:** The code locates all quotes and their corresponding authors from the parsed HTML. It targets elements with the class quote, which encapsulates each quote.\n",
        "\n",
        "# Output: Finally, it prints each quote along with the author to the console."
      ],
      "metadata": {
        "id": "OQBd689VyQJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we first install the web scraping python library called beautiful soup\n",
        "! pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N80cWILcyQZ4",
        "outputId": "50cb5bec-e41d-476d-8fb5-a3655366353f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then we display it to see if it is installed properly\n",
        "pip show beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mGbVrKiydvq",
        "outputId": "295a1bf2-8a20-4d6a-a3d1-b9dcfbcb4033"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: beautifulsoup4\n",
            "Version: 4.13.5\n",
            "Summary: Screen-scraping library\n",
            "Home-page: https://www.crummy.com/software/BeautifulSoup/bs4/\n",
            "Author: \n",
            "Author-email: Leonard Richardson <leonardr@segfault.org>\n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: soupsieve, typing-extensions\n",
            "Required-by: gdown, google, libpysal, nbconvert, yfinance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the website you want to scrape\n",
        "url = \"http://quotes.toscrape.com/\"  # Quotes to Scrape URL"
      ],
      "metadata": {
        "id": "EXUYDC_g4TVL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set user-agent to mimic a browser visit\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
        "}"
      ],
      "metadata": {
        "id": "9YcyWdtt4bUB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a GET request to the website\n",
        "response = requests.get(url, headers=headers)"
      ],
      "metadata": {
        "id": "TK82_rEg4gVN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all quote elements\n",
        "    quotes = soup.find_all('div', class_='quote')  # Each quote is in a div with class 'quote'\n",
        "\n",
        "    # Print the quotes and their authors\n",
        "    for quote in quotes:\n",
        "        text = quote.find('span', class_='text').get_text(strip=True)  # Extract the quote text\n",
        "        author = quote.find('small', class_='author').get_text(strip=True)  # Extract the author's name\n",
        "        print(f'Quote: {text}\\nAuthor: {author}\\n')\n",
        "\n",
        "else:\n",
        "    print(\"Error fetching the webpage:\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kzFloLK362x",
        "outputId": "3933176a-d42b-4a21-a5eb-336c4553e718"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quote: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
            "Author: Albert Einstein\n",
            "\n",
            "Quote: “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
            "Author: J.K. Rowling\n",
            "\n",
            "Quote: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
            "Author: Albert Einstein\n",
            "\n",
            "Quote: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
            "Author: Jane Austen\n",
            "\n",
            "Quote: “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
            "Author: Marilyn Monroe\n",
            "\n",
            "Quote: “Try not to become a man of success. Rather become a man of value.”\n",
            "Author: Albert Einstein\n",
            "\n",
            "Quote: “It is better to be hated for what you are than to be loved for what you are not.”\n",
            "Author: André Gide\n",
            "\n",
            "Quote: “I have not failed. I've just found 10,000 ways that won't work.”\n",
            "Author: Thomas A. Edison\n",
            "\n",
            "Quote: “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
            "Author: Eleanor Roosevelt\n",
            "\n",
            "Quote: “A day without sunshine is like, you know, night.”\n",
            "Author: Steve Martin\n",
            "\n"
          ]
        }
      ]
    }
  ]
}